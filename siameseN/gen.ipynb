{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import csv\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_files(path):\n",
    "    result = []\n",
    "    images = {'0001' : [], '0002' : [], '0003' : [], '0004' : [], '0005' : [], '0006' : [], '0007' : [], '0008' : [], '0009' : [], '0010' : [],'0011' : [], '0012' : [], '0013' : [], '0014' : [], '0015' : [], '0016' : []}\n",
    "    for root, dirs, files in os.walk(path):\n",
    "        for file in files:\n",
    "            if file.endswith('.bmp'):\n",
    "                result.append({\n",
    "                    'folder': os.path.basename(root),\n",
    "                    'filename': file\n",
    "                })\n",
    "                images[os.path.basename(root)].append(file)\n",
    "\n",
    "    return images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Real Faces\n",
      "Client #Images\n",
      "0001 249\n",
      "0002 57\n",
      "0003 113\n",
      "0004 681\n",
      "0005 190\n",
      "0006 730\n",
      "0007 762\n",
      "0008 123\n",
      "0009 213\n",
      "0010 76\n",
      "0011 409\n",
      "0012 435\n",
      "0013 472\n",
      "0014 477\n",
      "0015 118\n",
      "0016 0\n",
      "\n",
      "\n",
      "Fake Faces\n",
      "Client #Images\n",
      "0001 614\n",
      "0002 609\n",
      "0003 603\n",
      "0004 608\n",
      "0005 595\n",
      "0006 458\n",
      "0007 605\n",
      "0008 599\n",
      "0009 602\n",
      "0010 242\n",
      "0011 303\n",
      "0012 384\n",
      "0013 0\n",
      "0014 439\n",
      "0015 380\n",
      "0016 468\n"
     ]
    }
   ],
   "source": [
    "real_path = './NormalizedFace/ClientNormalized/'\n",
    "fake_path = './NormalizedFace/ImposterNormalized/'\n",
    "\n",
    "real = get_files(real_path)\n",
    "fake = get_files(fake_path)\n",
    "\n",
    "print('Real Faces\\nClient #Images')\n",
    "for folder in real.keys():\n",
    "    print(folder, len(real[folder]))\n",
    "\n",
    "print('\\n\\nFake Faces\\nClient #Images')\n",
    "for folder in fake.keys():\n",
    "    print(folder, len(fake[folder]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_folder_dataset(list1, list2, count, folder_name, path1, path2, label):\n",
    "    n = int(count ** 0.5 + 1)\n",
    "    l1 = random.sample(list1, n)\n",
    "    l2 = random.sample(list2, n)\n",
    "    result = []\n",
    "\n",
    "    for i in range(len(l1)):\n",
    "        for j in range(len(l2)):\n",
    "            result.append({\n",
    "                'img1' : path1 + folder_name + '/' + l1[i],\n",
    "                'img2' : path2 + folder_name + '/' + l2[j],\n",
    "                'label' : label\n",
    "            }) \n",
    "\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_dataset(real, fake, entryPerFace, folders):\n",
    "    dataset = []\n",
    "\n",
    "    for folder in folders:\n",
    "        result = make_folder_dataset(real[folder], real[folder], entryPerFace, folder, real_path, real_path, 1)\n",
    "        for i in range(len(result)):\n",
    "            dataset.append(result[i])\n",
    "\n",
    "    for folder in folders:\n",
    "        result = make_folder_dataset(real[folder], fake[folder], entryPerFace, folder, real_path, fake_path, 0)\n",
    "        for i in range(len(result)):\n",
    "            dataset.append(result[i])\n",
    "    \n",
    "    random.shuffle(dataset)\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of train dataset = 7056\n",
      "Length of validation dataset = 1024\n",
      "Length of test dataset = 2048\n"
     ]
    }
   ],
   "source": [
    "folders = ['0001', '0002', '0003', '0004', '0005', '0006', '0007', '0008', '0009', '0010', '0011', '0012', '0014', '0015']\n",
    "\n",
    "train_dataset = generate_dataset(real, fake, 400, folders[:8])\n",
    "valid_dataset = generate_dataset(real, fake, 250, folders[8:10])\n",
    "test_dataset = generate_dataset(real, fake, 250, folders[10:])\n",
    "\n",
    "print(\"Length of train dataset =\", len(train_dataset))\n",
    "print(\"Length of validation dataset =\", len(valid_dataset))\n",
    "print(\"Length of test dataset =\", len(test_dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_file(file_name, dataset):\n",
    "    random.shuffle(dataset)\n",
    "    with open(file_name, 'w', newline='') as output_file:\n",
    "        dict_writer = csv.DictWriter(output_file, dataset[0].keys())\n",
    "        dict_writer.writeheader()\n",
    "        dict_writer.writerows(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "write_file('train.csv', train_dataset)\n",
    "write_file('valid.csv', valid_dataset)\n",
    "write_file('test.csv', test_dataset)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
